TrainReader:
  inputs_def:
    fields: ['image', 'gt_bbox', 'gt_class', 'gt_score']
    num_max_boxes: 100
  dataset:
    !COCODataSet
      image_dir: train-data
      anno_path: annotations/1584811984_train_final.json
      dataset_dir: dataset/track1
      with_background: false
  sample_transforms:
    - !DecodeImage
      to_rgb: True
      with_mixup: False
    - !MixupImage
      alpha: 1.5
      beta: 1.5
    - !ColorDistort {}
    - !RandomExpand
      fill_value: [123.675, 116.28, 103.53]
    - !RandomCrop {}
    - !RandomFlipImage
      is_normalized: false
    - !NormalizeBox {}
    - !PadBox
      num_max_boxes: 100
    - !BboxXYXY2XYWH {}
  batch_transforms:
  - !RandomShape
    #sizes: [320, 352, 384, 416, 448, 480, 512, 544, 576, 608]
    sizes: [800, 864, 928, 960, 992]
    random_inter: True
  - !NormalizeImage
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
    is_scale: True
    is_channel_first: false
  - !Permute
    to_bgr: false
    channel_first: True
  # Gt2YoloTarget is only used when use_fine_grained_loss set as true,
  # this operator will be deleted automatically if use_fine_grained_loss
  # is set as false
  - !Gt2YoloTarget
    anchor_masks: [[6, 7, 8], [3, 4, 5], [0, 1, 2]]
    #anchors: [[10, 13], [16, 30], [33, 23],
    #          [30, 61], [62, 45], [59, 119],
    #          [116, 90], [156, 198], [373, 326]]
    ### v2x 4w
    anchors: [[8, 9], [10, 23], [19, 15],
              [23, 33], [40, 25], [54, 50],
              [101, 80], [139, 145], [253, 224]]
    downsample_ratios: [32, 16, 8]
  batch_size: 8
  shuffle: true
  #mixup_epoch: 250
  mixup_epoch: -1
  drop_last: true
  worker_num: 8
  bufsize: 32
  use_process: true


EvalReader:
  inputs_def:
    fields: ['image', 'im_size', 'im_id']
    num_max_boxes: 100
  dataset:
    !COCODataSet
      #image_dir: validation
      #anno_path: val_ignore_occlusion_cls12.json
      #dataset_dir: dataset/v2x-data-4w
      image_dir: '.'
      anno_path: aicity19_detection_label_add_small_object_0329_val.json
      dataset_dir: dataset/track1
      with_background: false
  sample_transforms:
    - !DecodeImage
      to_rgb: True
    - !ResizeImage
      #target_size: 608
      target_size: 960
      interp: 2
    - !NormalizeImage
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
      is_scale: True
      is_channel_first: false
    - !PadBox
      num_max_boxes: 50
    - !Permute
      to_bgr: false
      channel_first: True
  batch_size: 8
  drop_empty: false
  worker_num: 8
  bufsize: 32

TestReader:
  inputs_def:
    #image_shape: [3, 608, 608]
    image_shape: [3, 800, 800]
    #image_shape: [3, 960, 960]
    fields: ['image', 'im_size', 'im_id']
  dataset:
    !ImageFolder
      anno_path: annotations/instances_val2017.json
      with_background: false
  sample_transforms:
    - !DecodeImage
      to_rgb: True
    - !ResizeImage
      #target_size: 608
      target_size: 800
      #target_size: 960
      interp: 2
    - !NormalizeImage
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
      is_scale: True
      is_channel_first: false
    - !Permute
      to_bgr: false
      channel_first: True
  batch_size: 1
